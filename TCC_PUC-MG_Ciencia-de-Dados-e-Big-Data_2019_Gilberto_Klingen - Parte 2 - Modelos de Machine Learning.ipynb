{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  PUC - MG\n",
    "##  Ciência de Dados e Big Data - 2019\n",
    "##  TCC - Gilberto Klingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquisição de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtem_base_reduzida(base):\n",
    "    \n",
    "    # Esta função transforma duas colunas de mesmo significado em apenas uma contendo a diferença do valor relativo\n",
    "    # ao jogador 1 diminuída do valor relativo ao jogador 2\n",
    "    \n",
    "    base['pct_surface_victories_1'] = base['pct_surface_victories_1'] - base['pct_surface_victories_2']\n",
    "    base['pct_best_of_victories_1'] = base['pct_best_of_victories_1'] - base['pct_best_of_victories_2']\n",
    "    base['avg_ace_1'] = base['avg_ace_1'] - base['avg_ace_2']\n",
    "    base['avg_df_1'] = base['avg_df_1'] - base['avg_df_2']\n",
    "    base['avg_svpt_1'] = base['avg_svpt_1'] - base['avg_svpt_2']\n",
    "    base['avg_1stIn_1'] = base['avg_1stIn_1'] - base['avg_1stIn_2']\n",
    "    base['avg_1stWon_1'] = base['avg_1stWon_1'] - base['avg_1stWon_2']\n",
    "    base['avg_2ndWon_1'] = base['avg_2ndWon_1'] - base['avg_2ndWon_2']\n",
    "    base['avg_SvGms_1'] = base['avg_SvGms_1'] - base['avg_SvGms_2']\n",
    "    base['avg_bpSaved_1'] = base['avg_bpSaved_1'] - base['avg_bpSaved_2']\n",
    "    base['avg_bpFaced_1'] = base['avg_bpFaced_1'] - base['avg_bpFaced_2']\n",
    "    base['age_1'] = base['age_1'] - base['age_2']\n",
    "    base['rank_points_1'] = base['rank_points_1'] - base['rank_points_2']\n",
    "    base['pct_victories_grand_slam_1'] = base['pct_victories_grand_slam_1'] - base['pct_victories_grand_slam_2']\n",
    "    base['pct_victories_master_1000_1'] = base['pct_victories_master_1000_1'] - base['pct_victories_master_1000_2']\n",
    "    base['pct_victories_ATP_250_500_1'] = base['pct_victories_ATP_250_500_1'] - base['pct_victories_ATP_250_500_2']\n",
    "    base['pct_victories_finals_1'] = base['pct_victories_finals_1'] - base['pct_victories_finals_2']\n",
    "    base['qty_grand_slam_titles_1'] = base['qty_grand_slam_titles_1'] - base['qty_grand_slam_titles_2']\n",
    "    base['qty_master_1000_titles_1'] = base['qty_master_1000_titles_1'] - base['qty_master_1000_titles_2']\n",
    "    base['qty_ATP_250_500_titles_1'] = base['qty_ATP_250_500_titles_1'] - base['qty_ATP_250_500_titles_2']\n",
    "    base['qty_finals_titles_1'] = base['qty_finals_titles_1'] - base['qty_finals_titles_2']\n",
    "\n",
    "    base['pct_player_1_surface_victories'] = base['pct_player_1_surface_victories'] - base['pct_player_2_surface_victories']\n",
    "    base['pct_player_1_best_of_victories'] = base['pct_player_1_best_of_victories'] - base['pct_player_2_best_of_victories']\n",
    "    base['pct_player_1_grand_slam_victories'] = base['pct_player_1_grand_slam_victories'] - base['pct_player_2_grand_slam_victories']\n",
    "    base['pct_player_1_master_1000_victories'] = base['pct_player_1_master_1000_victories'] - base['pct_player_2_master_1000_victories']\n",
    "    base['pct_player_1_finals_victories'] = base['pct_player_1_finals_victories'] - base['pct_player_2_finals_victories']\n",
    "    base['pct_player_1_ATP_250_500_victories'] = base['pct_player_1_ATP_250_500_victories'] - base['pct_player_2_ATP_250_500_victories']\n",
    "\n",
    "    base = base.drop(['pct_surface_victories_2','pct_best_of_victories_2','avg_ace_2','avg_df_2','avg_svpt_2','avg_1stIn_2',\n",
    "                      'avg_1stWon_2','avg_2ndWon_2','avg_SvGms_2','avg_bpSaved_2','avg_bpFaced_2','age_2','rank_points_2',\n",
    "                      'pct_victories_grand_slam_2','pct_victories_master_1000_2','pct_victories_ATP_250_500_2',\n",
    "                      'pct_victories_finals_2','qty_grand_slam_titles_2','qty_master_1000_titles_2','qty_ATP_250_500_titles_2',\n",
    "                      'qty_finals_titles_2','pct_player_2_surface_victories','pct_player_2_best_of_victories',\n",
    "                      'pct_player_2_grand_slam_victories','pct_player_2_master_1000_victories','pct_player_2_finals_victories',\n",
    "                      'pct_player_2_ATP_250_500_victories'],axis=1)\n",
    "    \n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtem a base completa de jogos para análise\n",
    "\n",
    "base_completa = pd.read_excel(r'C:\\Giba\\Dados\\_A_Giba\\Documentos\\Adm\\PUC_MG\\Python\\Bases_ML\\base_completa.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera a base completa redefinida, onde os valores irão de 0,0 a 1,0 e exclui as colunas não relevantes\n",
    "\n",
    "base_redefinida = base_completa.drop(['tourney_id','tourney_date','match_num','round','surface','tourney_level',\n",
    "                                      'best_of','AvgW','AvgL','player_id_1','player_id_2'],axis=1)\n",
    "base_redefinida = base_redefinida.apply(lambda x: round(x / 100,4))\n",
    "base_redefinida['rank_points_1'] = base_redefinida['rank_points_1'].apply(lambda x: round(x / 1000,4))\n",
    "base_redefinida['rank_points_2'] = base_redefinida['rank_points_2'].apply(lambda x: round(x / 1000,4))\n",
    "base_redefinida['winner'] = base_redefinida['winner'].apply(lambda x: x * 100)\n",
    "base_redefinida.to_excel(r'C:\\Giba\\Dados\\_A_Giba\\Documentos\\Adm\\PUC_MG\\Python\\Bases_ML\\base_redefinida.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera a base completa reduzida, onde as colunas do jogador 1 e 2 foram reduzidas a apenas uma contendo a diferença\n",
    "# de seus valores\n",
    "\n",
    "base_ML = obtem_base_reduzida(base_redefinida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gera o Modelo de Machine Learning utilizando o algoritmo de regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa as colunas de dimensões da base\n",
    "\n",
    "X = base_ML.iloc[:,0:(base_ML.shape[1] - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa a coluna de classe de classificação da base\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(base_ML.iloc[:,(base_ML.shape[1] - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a separação das bases de treinamento e teste (20% da base será para treinamento)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executa o treinamento do modelo\n",
    "\n",
    "LogisticRegr = LogisticRegression(max_iter=1000)\n",
    "LogisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o modelo na base de teste\n",
    "\n",
    "y_pred = LogisticRegr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7799417953884038\n"
     ]
    }
   ],
   "source": [
    "# Verifica a acurácia do modelo\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78      4433\n",
      "           1       0.80      0.75      0.77      4501\n",
      "\n",
      "    accuracy                           0.78      8934\n",
      "   macro avg       0.78      0.78      0.78      8934\n",
      "weighted avg       0.78      0.78      0.78      8934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verifica a performance de classificação do modelo\n",
    "\n",
    "print(classification_report( y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Player_1 (prev)  Player_2 (prev)\n",
      "Player_1             3585              848\n",
      "Player_2             1118             3383\n"
     ]
    }
   ],
   "source": [
    "# Verifica a matriz de confusão do modelo\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "cnf_table = pd.DataFrame(data=confusion, index=[\"Player_1\", \"Player_2\"], columns=[\"Player_1 (prev)\", \"Player_2 (prev)\"])\n",
    "print(cnf_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04522779, 0.95477221],\n",
       "       [0.65610069, 0.34389931],\n",
       "       [0.69694679, 0.30305321],\n",
       "       ...,\n",
       "       [0.59641974, 0.40358026],\n",
       "       [0.32990118, 0.67009882],\n",
       "       [0.70340496, 0.29659504]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gera a matriz de probabilidades da base completa\n",
    "\n",
    "prb = LogisticRegression(random_state=0,max_iter=1000).fit(X, y)\n",
    "prb.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva a matriz de probabilidades em uma planilha Excel\n",
    "\n",
    "df_odds = pd.DataFrame(prb.predict_proba(X))\n",
    "df_odds.to_excel(\"C:\\\\Giba\\Dados\\\\_A_Giba\\\\Documentos\\\\Adm\\\\PUC_MG\\\\Python\\\\Bases_ML\\\\odds_predict_logistic_regression.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gera o Modelo de Machine Learning utilizando o algoritmo de árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As etapas de separação das colunas de dimensão e da coluna de classe de classificação da base e\n",
    "# separação das bases de treinamento e teste já foram executadas na criação do modelo através do algoritmo de \n",
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa o treinamento do modelo\n",
    "\n",
    "# odds_tree = DecisionTreeClassifier(random_state=0, criterion='gini',min_samples_leaf=5,min_samples_split=5,max_depth=None)\n",
    "odds_tree = DecisionTreeClassifier(random_state=0, criterion='entropy')\n",
    "odds_tree = odds_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o modelo na base de teste\n",
    "\n",
    "y_pred = odds_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9937318110588762\n"
     ]
    }
   ],
   "source": [
    "# Verifica a acurácia do modelo\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Player_1       1.00      0.99      0.99      4433\n",
      "    Player_2       0.99      1.00      0.99      4501\n",
      "\n",
      "    accuracy                           0.99      8934\n",
      "   macro avg       0.99      0.99      0.99      8934\n",
      "weighted avg       0.99      0.99      0.99      8934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verifica a performance de classificação do modelo\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Player_1\", \"Player_2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Player_1 (prev)  Player_2 (prev)\n",
      "Player_1             4399               34\n",
      "Player_2               22             4479\n"
     ]
    }
   ],
   "source": [
    "# Verifica a matriz de confusão do modelo\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cnf_table = pd.DataFrame(data=cnf_matrix, index=[\"Player_1\", \"Player_2\"], columns=[\"Player_1 (prev)\", \"Player_2 (prev)\"])\n",
    "print(cnf_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gera a matriz de probabilidades da base completa\n",
    "\n",
    "prb = DecisionTreeClassifier(random_state=0, criterion='entropy').fit(X, y)\n",
    "prb.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gera o Modelo de Machine Learning utilizando o algoritmo de Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As etapas de separação das colunas de dimensão e da coluna de classe de classificação da base e\n",
    "# separação das bases de treinamento e teste já foram executadas na criação do modelo através do algoritmo de \n",
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executa o treinamento do modelo\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o modelo na base de teste\n",
    "\n",
    "y_pred = gnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9975374972017014\n"
     ]
    }
   ],
   "source": [
    "# Verifica a acurácia do modelo\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Player_1       1.00      1.00      1.00      4433\n",
      "    Player_2       1.00      1.00      1.00      4501\n",
      "\n",
      "    accuracy                           1.00      8934\n",
      "   macro avg       1.00      1.00      1.00      8934\n",
      "weighted avg       1.00      1.00      1.00      8934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verifica a performance de classificação do modelo\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Player_1\", \"Player_2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Player_1 (prev)  Player_2 (prev)\n",
      "Player_1             4433                0\n",
      "Player_2               22             4479\n"
     ]
    }
   ],
   "source": [
    "# Verifica a matriz de confusão do modelo\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cnf_table = pd.DataFrame(data=cnf_matrix, index=[\"Player_1\", \"Player_2\"], columns=[\"Player_1 (prev)\", \"Player_2 (prev)\"])\n",
    "print(cnf_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gera a matriz de probabilidades da base completa\n",
    "\n",
    "prb = DecisionTreeClassifier(random_state=0, criterion='entropy').fit(X, y)\n",
    "prb.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
